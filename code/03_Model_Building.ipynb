{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3754c5e-cf77-47ac-ac81-0120f9cb3cb7",
   "metadata": {},
   "source": [
    "# Ames Housing Data: Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73412b5-210e-4362-b175-8561578ad164",
   "metadata": {},
   "source": [
    "In this notebook, we will be model-building by iterating across various features to find which ones are most associated with sales price after accounting for the interplay between variables. We will run our variables through four methods of linear regression.\n",
    "\n",
    "1. Linear Regression <u>**Without**</u> Log-Transformed Target Variable\n",
    "2. Linear Regression <u>**With**</u> Log-Transformed Target Variable\n",
    "3. Linear Regression <u>**With**</u> Log-Transformed Target Variable and RidgeCV Regularization\n",
    "4. Linear Regression <u>**With**</u> Log-Transformed Target Variable and LassoCV Regularization\n",
    "\n",
    "For more information on the initial data cleaning, exploration, and visualization see the [initial notebook](../code/01_EDA_and_Cleaning.ipynb) of this analysis. For transforming our variables into model-ready form, see the [second notebook](../code/02_Feature_Engineering.ipynb) of this analysis.\n",
    "\n",
    "For more information on the background, [data](https://jse.amstat.org/v19n3/decock/DataDocumentation.txt), and a summary of methods and findings, please see the associated [README](../Farah_Malik_Proj2_README.md) for this analysis.\n",
    "\n",
    "### Contents:\n",
    "- [I. Model Building and Testing](#I.-Model-Building-and-Testing)\n",
    "    - [Sales Price - Not Log Transformed](#Modeling-Sale-Price-Modeling-(Not-Log-Transformed))\n",
    "    - [Sales Price - Log Transformed](#Modeling-Sale-Price-Modeling-(Log-Transformed))\n",
    "- [II. Regularization](#II.-Regularization)\n",
    "    - [Ridge CV](#Ridge-CV)\n",
    "    - [Lasso CV](#Lasso-CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbba05d-098d-4b61-afe8-e787c98846da",
   "metadata": {},
   "source": [
    "## I. Model Building and Testing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b69bbb86-16de-4612-8830-ebb471de161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import missingno as msno\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder #, PolynomialFeatures\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30bab665-97ab-4855-a3f4-698327d091f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = pd.read_csv('../datasets/Clean/train.csv', na_values=['NaN', '', 'Missing'], keep_default_na=False)\n",
    "hs_test = pd.read_csv('../datasets/Clean/test.csv', na_values=['NaN', '', 'Missing'], keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51678c8b-846d-43fe-bb49-373d2ef1e50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id', 'ms_subclass', 'ms_zoning', 'lot_frontage', 'lot_area', 'street', 'lot_shape', 'land_contour', 'utilities', 'lot_config', 'land_slope', 'neighborhood', 'condition_1', 'condition_2', 'bldg_type', 'house_style', 'overall_qual', 'overall_cond', 'year_built', 'year_remod', 'roof_style', 'roof_matl', 'exterior_1st', 'exterior_2nd', 'mas_vnr_type', 'mas_vnr_area', 'exter_qual', 'exter_cond', 'foundation', 'bsmt_qual', 'bsmt_cond', 'bsmt_exposure', 'bsmtfin_type_1', 'bsmtfin_sf_1', 'bsmtfin_type_2', 'bsmtfin_sf_2', 'bsmt_unf_sf', 'total_bsmt_sf', 'heating', 'heating_qc', 'central_air', 'electrical', '1st_flr_sf', '2nd_flr_sf', 'low_qual_fin_sf', 'gr_liv_area', 'bsmt_full_bath', 'bsmt_half_bath', 'full_bath', 'half_bath', 'bedroom_abvgr', 'kitchen_abvgr', 'kitchen_qual', 'totrms_abvgrd', 'functional', 'fireplaces', 'fireplace_qu', 'garage_type', 'garage_yr_blt', 'garage_finish', 'garage_cars', 'garage_area', 'garage_qual', 'garage_cond', 'paved_drive', 'wood_deck_sf', 'open_porch_sf', 'enclosed_porch', '3ssn_porch', 'screen_porch', 'pool_area', 'misc_val', 'mo_sold', 'yr_sold', 'sale_type', 'SalePrice', 'bsmt_fin_cat', 'overall_qual_cond', 'age', 'age_adj', 'was_remod', 'bsmt_cond_num', 'log_price', 'bsmt_cat', 'bsmt_cat_finished', 'bsmt_cat_unfinished', 'grg_qual_num', 'garage_cat', 'garage_cat_finished', 'garage_cat_rough_finished', 'garage_cat_unfinished', 'fireplace_cat', 'fireplace_cat_hi_qual', 'fireplace_cat_low_qual', 'kitchen_qual_Fa', 'kitchen_qual_Gd', 'kitchen_qual_TA', 'cond12', 'cond12_feeder_st', 'cond12_near_park', 'cond12_near_rr', 'cond12_norm', 'lotconfig', 'lotconfig_culdsac', 'lotconfig_inside', 'hi_bsmt_exposure', 'has_pool', 'amenities_scr', 'nbr_med', 'nbr_qual', 'ext_qu_scr', 'nbr_ext', 'func_scr', 'nbr_func', 'nbr_amen', 'nbr_rank'] "
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "print(hs.columns.tolist(), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00468720-5921-479a-846c-b89802a503dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE FEATURES FOR TESTING HERE\n",
    "feats_updated = ['overall_qual', 'year_built', 'year_remod', 'total_bsmt_sf', 'gr_liv_area', 'full_bath', 'fireplaces', 'age', 'garage_area', 'kitchen_qual_Fa',\n",
    " 'kitchen_qual_Gd', 'kitchen_qual_TA', 'was_remod', 'bsmt_cat_finished','bsmt_cat_unfinished', 'grg_qual_num', 'garage_cat_finished', 'garage_cat_unfinished', 'garage_cat_rough_finished', 'cond12_feeder_st',\n",
    " 'cond12_near_park', 'cond12_near_rr', 'cond12_norm', 'lotconfig_culdsac', 'lotconfig_inside', 'hi_bsmt_exposure', 'nbr_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974444d5-b957-4101-b2b1-ff696fa70578",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Modeling Sale Price (Not Log Transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d672eab-164c-4bd4-b46a-9f2a01e987ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_qual: 11804.824274025836\n",
      "year_built: -410.5353268900927\n",
      "year_remod: 172.00976309426602\n",
      "total_bsmt_sf: 34.30426812411277\n",
      "gr_liv_area: 52.17362331117928\n",
      "full_bath: -8145.517803792539\n",
      "fireplaces: 6412.174583419767\n",
      "age: -553.5199622532209\n",
      "garage_area: 43.71183061537619\n",
      "kitchen_qual_Fa: -53701.51691238236\n",
      "kitchen_qual_Gd: -51089.166041880686\n",
      "kitchen_qual_TA: -56445.04567581338\n",
      "was_remod: 8142.983106854677\n",
      "bsmt_cat_finished: -21644.16920072713\n",
      "bsmt_cat_unfinished: -31213.474983927346\n",
      "grg_qual_num: 9866.08968427968\n",
      "garage_cat_finished: -31071.90266447083\n",
      "garage_cat_unfinished: -36015.396668255395\n",
      "garage_cat_rough_finished: -37774.44812588643\n",
      "cond12_feeder_st: 8112.763353697516\n",
      "cond12_near_park: 28556.98071340498\n",
      "cond12_near_rr: 9932.878439017215\n",
      "cond12_norm: 12892.289059668099\n",
      "lotconfig_culdsac: 10641.477926450098\n",
      "lotconfig_inside: 1367.2451261571337\n",
      "hi_bsmt_exposure: 10308.998256744513\n",
      "nbr_rank: 1612.944007931598\n",
      "intercept: 510191.0751264385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training R2: 0.8809534470072595, Testing R2: 0.8710097545600572, MSE: 764785529.9624298, RMSE: 27654.75600981556'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mod_iteration(feats):\n",
    "    \n",
    "    # Fit regression to X_train and y_train (75% of training.csv)\n",
    "    X = hs[feats]\n",
    "    y = hs['SalePrice']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 531)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict SalePrice for 25% testing data within train.csv and compare to truth to get residuals\n",
    "    y_preds = lr.predict(X_test)\n",
    "    MSE = metrics.mean_squared_error(y_test, y_preds)\n",
    "    RMSE = metrics.mean_squared_error(y_test, y_preds, squared=False)\n",
    "        \n",
    "    for i, coef in zip(X.columns, lr.coef_):\n",
    "        print(f\"{i}: {coef}\")\n",
    "    print(f\"intercept: {lr.intercept_}\")\n",
    "    \n",
    "    return f\"Training R2: {lr.score(X_train, y_train)}, Testing R2: {lr.score(X_test, y_test)}, MSE: {MSE}, RMSE: {RMSE}\"\n",
    "    \n",
    "mod_iteration(feats_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63e99138-ef81-48ec-b527-e971d9c441b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_qual: 12151.581022899345\n",
      "year_built: -585.8462202756798\n",
      "year_remod: 196.31828856779129\n",
      "total_bsmt_sf: 34.31428826277168\n",
      "gr_liv_area: 52.842223083098915\n",
      "full_bath: -7841.326090856938\n",
      "fireplaces: 6596.682174842231\n",
      "age: -717.3638658946714\n",
      "garage_area: 41.75916216027622\n",
      "kitchen_qual_Fa: -51807.77565446007\n",
      "kitchen_qual_Gd: -50797.037977397646\n",
      "kitchen_qual_TA: -54888.96195427756\n",
      "was_remod: 7724.500327376971\n",
      "bsmt_cat_finished: -18042.387453871354\n",
      "bsmt_cat_unfinished: -28049.355525139814\n",
      "grg_qual_num: 6232.194797085448\n",
      "garage_cat_finished: -21465.53690297896\n",
      "garage_cat_unfinished: -26616.58590005632\n",
      "garage_cat_rough_finished: -27280.76094591148\n",
      "cond12_feeder_st: 4549.895677239171\n",
      "cond12_near_park: 22312.175512042628\n",
      "cond12_near_rr: 5579.578959396819\n",
      "cond12_norm: 10417.619381909264\n",
      "lotconfig_culdsac: 10031.469434333692\n",
      "lotconfig_inside: -85.38044764889618\n",
      "hi_bsmt_exposure: 11113.917100889583\n",
      "nbr_rank: 1548.2313114093179\n",
      "intercept: 811928.219295017\n",
      "null_MSE: 6209949084.095235, null_RMSE: 78803.2301628254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Full Data R2: 0.8790536004573352, MSE = 751070983.064588, RMSE = 27405.67428589539'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mod_runon_all(feats):\n",
    "    \n",
    "    # Fit regression to entire data\n",
    "    X = hs[feats]\n",
    "    y = hs['SalePrice']\n",
    "    lr_all = LinearRegression()\n",
    "    lr_all.fit(X, y)\n",
    "    \n",
    "    # Predict SalePrice for entire data and compare to truth to get residuals\n",
    "    y_preds_all = lr_all.predict(hs[feats])\n",
    "    y_true = hs['SalePrice'] #Can use var from entire dataset\n",
    "    MSE = metrics.mean_squared_error(y_true, y_preds_all)\n",
    "    RMSE = metrics.mean_squared_error(y_true, y_preds_all, squared=False)\n",
    "    \n",
    "    # Use regression to predict SalePrice on Test.csv (unseen) data\n",
    "    y_preds_all_test = lr_all.predict(hs_test[feats])\n",
    "    hs_test['SalePrice'] = y_preds_all_test\n",
    "    \n",
    "    # Null model for comparison\n",
    "    hs['null_pred'] = np.mean(y)\n",
    "    null_pred = hs['null_pred']\n",
    "    null_MSE = metrics.mean_squared_error(y_true, null_pred)\n",
    "    null_RMSE = metrics.mean_squared_error(y_true, null_pred, squared=False)\n",
    "    \n",
    "    # Submit Predictions to Kaggle\n",
    "    #submit = hs_test[['Id', 'SalePrice']]\n",
    "    #submit.set_index('Id', inplace=True)\n",
    "    #dt = datetime.datetime.now().strftime(\"%m%d%Y%H\")\n",
    "    #submit.to_csv(f'../datasets/Submissions/Features_Submission-{dt}.csv')\n",
    "        \n",
    "    for i, coef in zip(X.columns, lr_all.coef_):\n",
    "        print(f\"{i}: {coef}\")\n",
    "    print(f\"intercept: {lr_all.intercept_}\")\n",
    "    print(f\"null_MSE: {null_MSE}, null_RMSE: {null_RMSE}\")\n",
    "    \n",
    "    return f\"Full Data R2: {lr_all.score(X, y)}, MSE = {MSE}, RMSE = {RMSE}\"\n",
    "\n",
    "mod_runon_all(feats_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4224316c-0f45-4e2c-a481-945b290927c3",
   "metadata": {},
   "source": [
    "<span style= 'color:blue'>**Under this linear model where the target variable (Sale Price) <u>was not</u> log-transformed, our training and testing R^2 were similar: 88% and 87%, respectively. This indicates that the model is not overfit, and that ~87% of the variability in Sale Price can be explained by the features used in our model. With an RMSE of 27,405 (fitted on the whole data), this model does a much better job than the null model of predicting Sale Price (null_RMSE: 78,803).**</span>\n",
    "\n",
    "<span style= 'color:blue'>**Some noteable model features included:</span>\n",
    "- <span style= 'color:blue'>**_Fireplaces_**: For every increase of one fireplace in the property, the predicted Sale Price increased by ~\\\\$6,596, holding all other variables constant.</span>\n",
    "- <span style= 'color:blue'>**_Age_**: For every one year increase in age of property, the prediced Sale Price decreased by \\\\$717, holding all other variables constant.</span>\n",
    "- <span style= 'color:blue'>**_Kitchen Quality_**: Holding all other variables constant, having a kitchen in Fair quality vs. Excellent quality decreased the predicted Sale Price by \\\\$51,807. Even having a Good kitchen vs. an Excellent one decreased predicted Sale Price by \\\\$50,797.</span>\n",
    "- <span style= 'color:blue'>**_Remodeling_**: Holding all other variables constant, properties that had undergone remodeling increased in the predicted Sale Price on average by \\\\$7,724.</span>\n",
    "- <span style= 'color:blue'>**_Basement Exposure_**: Having high basement exposure (e.g., walk-out basement, garden level walls, natural light) was associated with a predicted Sale Price of \\\\$11,113 larger than not having high basement high basement exposure, holding all other variables constant</span>\n",
    "- <span style= 'color:blue'>**_Lot Configuration_**: Holding all other variables constant, the Sale Price of a cul-de-sac was predicted to be \\\\$10,031 higher than a corner unit. A corner unit, however, had higher predicted Sale Prices than inside lot - for inside lots, the predicted Sale Price decreased by \\\\$85 compared to a corner lot.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be0808-15ec-45a9-a8d3-cc89e615c2a4",
   "metadata": {},
   "source": [
    "### Modeling Sale Price (Log Transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2336342b-2580-4345-913f-d7c9334b1f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_qual: 1.0649930257040596\n",
      "year_built: 0.997328326731778\n",
      "year_remod: 1.002028242037629\n",
      "total_bsmt_sf: 1.0001454538552237\n",
      "gr_liv_area: 1.0002564586510467\n",
      "full_bath: 0.9855419914410289\n",
      "fireplaces: 1.0515311608010953\n",
      "age: 0.9964379435669756\n",
      "garage_area: 1.0001368435489209\n",
      "kitchen_qual_Fa: 0.8337583509783775\n",
      "kitchen_qual_Gd: 0.9083965913977291\n",
      "kitchen_qual_TA: 0.8769744321001228\n",
      "was_remod: 1.009637896122197\n",
      "bsmt_cat_finished: 1.0115078130951194\n",
      "bsmt_cat_unfinished: 0.9432869011987438\n",
      "grg_qual_num: 1.0663610999927287\n",
      "garage_cat_finished: 0.9275337260902414\n",
      "garage_cat_unfinished: 0.903813073448707\n",
      "garage_cat_rough_finished: 0.9170257092128509\n",
      "cond12_feeder_st: 1.0683746335567368\n",
      "cond12_near_park: 1.1614864510465106\n",
      "cond12_near_rr: 1.0803118340479656\n",
      "cond12_norm: 1.0972223758833322\n",
      "lotconfig_culdsac: 1.029965060606294\n",
      "lotconfig_inside: 0.9941061409721528\n",
      "hi_bsmt_exposure: 1.0352303887843572\n",
      "nbr_rank: 1.0065833584647488\n",
      "intercept: 210777.0370283581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training R2: 0.9028044824964966, Testing R2: 0.8469805826747016, MSE: 646845076.6517401, RMSE: 25433.14916898299'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_mod_iteration(feats):\n",
    "    \n",
    "    # Fit regression to X_train and y_train (75% of training.csv)\n",
    "    X = hs[feats]\n",
    "    y = hs['log_price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 531)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "        \n",
    "    # Predict SalePrice for 25% testing data within train.csv and compare to truth to get residuals\n",
    "    y_preds = np.exp(lr.predict(X_test)) # Undoing the logged price\n",
    "    MSE = metrics.mean_squared_error(np.exp(y_test), y_preds)\n",
    "    RMSE = metrics.mean_squared_error(np.exp(y_test), y_preds, squared=False)\n",
    "        \n",
    "    for i, coef in zip(X.columns, np.exp(lr.coef_)):\n",
    "        print(f\"{i}: {coef}\")\n",
    "    print(f\"intercept: {np.exp(lr.intercept_)}\")\n",
    "    \n",
    "    return f\"Training R2: {lr.score(X_train, y_train)}, Testing R2: {lr.score(X_test, y_test)}, MSE: {MSE}, RMSE: {RMSE}\"\n",
    "    \n",
    "log_mod_iteration(feats_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf7b8344-8281-4268-90d8-9311a4e041c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_qual: 1.0696865535392057\n",
      "year_built: 0.9959033162525016\n",
      "year_remod: 1.002016109483604\n",
      "total_bsmt_sf: 1.000145819116516\n",
      "gr_liv_area: 1.0002620830250117\n",
      "full_bath: 0.9827221661600672\n",
      "fireplaces: 1.0485701527856872\n",
      "age: 0.995148746389361\n",
      "garage_area: 1.000112803949039\n",
      "kitchen_qual_Fa: 0.8362399349796291\n",
      "kitchen_qual_Gd: 0.91334882606626\n",
      "kitchen_qual_TA: 0.8893959546874888\n",
      "was_remod: 1.0111401480164193\n",
      "bsmt_cat_finished: 1.0343143331644078\n",
      "bsmt_cat_unfinished: 0.9604765127312241\n",
      "grg_qual_num: 1.069397456003843\n",
      "garage_cat_finished: 0.9177955327307376\n",
      "garage_cat_unfinished: 0.8893246786037156\n",
      "garage_cat_rough_finished: 0.9081651198899384\n",
      "cond12_feeder_st: 1.0556430807336048\n",
      "cond12_near_park: 1.1352560495699646\n",
      "cond12_near_rr: 1.0581557791699316\n",
      "cond12_norm: 1.0817343297621271\n",
      "lotconfig_culdsac: 1.0227249064369153\n",
      "lotconfig_inside: 0.9867104691697841\n",
      "hi_bsmt_exposure: 1.0402720139384496\n",
      "nbr_rank: 1.0070666696308654\n",
      "intercept: 3668821.8353902274\n",
      "null_MSE: 6410615844.843487, null_RMSE: 80066.32153935565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Full Data R2: 0.8892826104265844, MSE = 545503324.5779072, RMSE = 23356.012600140188'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_mod_runon_all(feats):\n",
    "    \n",
    "    # Fit regression to entire data\n",
    "    X = hs[feats]\n",
    "    y = hs['log_price']\n",
    "    lr_all = LinearRegression()\n",
    "    lr_all.fit(X, y)\n",
    "    \n",
    "    # Predict SalePrice for entire data and compare to truth to get residuals\n",
    "    y_preds_all = np.exp(lr_all.predict(hs[feats]))\n",
    "    y_true = hs['SalePrice'] #Can use var from entire dataset\n",
    "    MSE = metrics.mean_squared_error(y_true, y_preds_all)\n",
    "    RMSE = metrics.mean_squared_error(y_true, y_preds_all, squared=False)\n",
    "    \n",
    "    # Use regression to predict SalePrice on Test.csv (unseen) data\n",
    "    y_preds_all_test = np.exp(lr_all.predict(hs_test[feats]))\n",
    "    hs_test['SalePrice'] = y_preds_all_test\n",
    "    \n",
    "    # Null model for comparison\n",
    "    hs['null_pred'] = np.exp(np.mean(y))\n",
    "    null_pred = hs['null_pred']\n",
    "    null_MSE = metrics.mean_squared_error(y_true, null_pred)\n",
    "    null_RMSE = metrics.mean_squared_error(y_true, null_pred, squared=False)\n",
    "    \n",
    "    # Submit Predictions to Kaggle\n",
    "    #submit = hs_test[['Id', 'SalePrice']]\n",
    "    #submit.set_index('Id', inplace=True)\n",
    "    #dt = datetime.datetime.now().strftime(\"%m%d%Y%H\")\n",
    "    #submit.to_csv(f'../datasets/Submissions/Features_Submission_logy-{dt}.csv')\n",
    "        \n",
    "    for i, coef in zip(X.columns, np.exp(lr_all.coef_)):\n",
    "        print(f\"{i}: {coef}\")\n",
    "    print(f\"intercept: {np.exp(lr_all.intercept_)}\")\n",
    "    print(f\"null_MSE: {null_MSE}, null_RMSE: {null_RMSE}\")\n",
    "    \n",
    "    return f\"Full Data R2: {lr_all.score(X, y)}, MSE = {MSE}, RMSE = {RMSE}\"\n",
    "\n",
    "log_mod_runon_all(feats_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8471afc-1b8d-4715-8c96-f0cd2cb1b346",
   "metadata": {},
   "source": [
    "<span style= 'color:blue'>**Under this linear model where the target variable (Sale Price) <u>was</u> log-transformed, our training and testing R^2 were approximately 5% different: 90% and 85%, respectively. This could potentially indicate some overfitting and is interpreted as: ~85% of the variability in Sale Price can be explained by the features used in our model. With an RMSE of 23,356 (fitted on the whole data), this model does a much better job than the null model of predicting Sale Price (null_RMSE: 80,066).**</span>\n",
    "\n",
    "<span style= 'color:blue'>**Some noteable model features included:</span>\n",
    "- <span style= 'color:blue'>**_Fireplaces_**: For every increase of one fireplace in the property, the predicted Sale Price increased by ~5%, holding all other variables constant.</span>\n",
    "- <span style= 'color:blue'>**_Kitchen Quality_**: Holding all other variables constant, having a kitchen in Fair quality vs. Excellent quality decreased the predicted Sale Price by 16%. Even having a Good kitchen vs. an Excellent one decreased predicted Sale Price by 9%.</span>\n",
    "- <span style= 'color:blue'>**_Basement Exposure_**: Having high basement exposure (e.g., walk-out basement, garden level walls, natural light) was associated with a predicted Sale Price of 5% larger than not having high basement high basement exposure, holding all other variables constant</span>\n",
    "- <span style= 'color:blue'>**_Proximity to Certian Conditions_**: Holding all other variables constant, the Sale Price of properties near/adjacent to amenties such as park, greenbelt, etc. was predicted to be 13.5% higher than if the property was adjacent to a large arterial street. Properties near a smaller feeder street or a railroad were had predicted Sale Prices that were higher by 5-6% compared to properties adjacent to arterial streets.</span>\n",
    "- <span style= 'color:blue'>**_Garage Quality vs. Finished Status_**: Holding all other variables constant, per every one unit increase in the garage quality (ordered from None, Poor, Fair, Average, Good, Excellent), the predicted Sale price was expected to increase by 7%. However, having a finished, rough finished, or unfinished garage, compared to no garage, appeared to be decrease the predicted Sale Price from 8-11%, holding all else equal. These results are unexpected and could potentially be due to multicollinearity taking place in the model between these features.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6f1814-ce0d-4d19-96fe-469aefed655d",
   "metadata": {},
   "source": [
    "---\n",
    "### II. Regularization\n",
    "Our model is overfit, as reflected by the R^2 for our training data being comfortably higher than the R^2 on our testing data. This indicates that our model is not doing as well on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5908376e-68ee-4ead-9e3b-0964f241715a",
   "metadata": {},
   "source": [
    "#### Ridge CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b61d07e-270a-4a58-a675-4ff9b7cd7cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_qual: 1.0929868252001564\n",
      "year_built: 1.003262771814451\n",
      "year_remod: 1.0411226928538944\n",
      "total_bsmt_sf: 1.0694591125867974\n",
      "gr_liv_area: 1.129637652218369\n",
      "full_bath: 0.9991057228617918\n",
      "fireplaces: 1.0322852082795653\n",
      "age: 0.9823141844380772\n",
      "garage_area: 1.0291470631894004\n",
      "kitchen_qual_Fa: 0.9746680412736631\n",
      "kitchen_qual_Gd: 0.9647569783781011\n",
      "kitchen_qual_TA: 0.9530320364108376\n",
      "was_remod: 1.0068839246749552\n",
      "bsmt_cat_finished: 1.012127930693443\n",
      "bsmt_cat_unfinished: 0.9811754889764924\n",
      "grg_qual_num: 1.0205010605422733\n",
      "garage_cat_finished: 1.010191943874786\n",
      "garage_cat_unfinished: 0.9914120521285621\n",
      "garage_cat_rough_finished: 1.0032891744958643\n",
      "cond12_feeder_st: 1.0064821214970217\n",
      "cond12_near_park: 1.0176827774784885\n",
      "cond12_near_rr: 1.0104551324378386\n",
      "cond12_norm: 1.023147186400762\n",
      "lotconfig_culdsac: 1.0042727178148587\n",
      "lotconfig_inside: 0.9941119244263893\n",
      "hi_bsmt_exposure: 1.018112668745832\n",
      "nbr_rank: 1.0418035451136785\n",
      "intercept: 168613.18234487195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training R2: 0.9028823969984556, Testing R2: 0.8391637960587384, MSE: 602610072.3548315, RMSE: 24548.117491058892'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_mod_iteration_rreg(feats):\n",
    "    \n",
    "    # Fit regression to X_train and y_train (75% of training.csv)\n",
    "    X = hs[feats]\n",
    "    y = hs['log_price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 602)\n",
    "    \n",
    "    # Scale features\n",
    "    sc = StandardScaler()\n",
    "    Z_train = sc.fit_transform(X_train)\n",
    "    Z_test = sc.transform(X_test)\n",
    "    \n",
    "    # Run Ridge Regression\n",
    "    r_alphas = np.logspace(0, 5, 150)\n",
    "    ridge_cv = RidgeCV(alphas = r_alphas, scoring = 'r2', cv = 10)\n",
    "    ridge_cv.fit(Z_train, y_train)\n",
    "            \n",
    "    # Predict SalePrice for 25% testing data within train.csv and compare to truth to get residuals\n",
    "    y_preds = np.exp(ridge_cv.predict(Z_test)) # Undoing the logged price\n",
    "    MSE = metrics.mean_squared_error(np.exp(y_test), y_preds)\n",
    "    RMSE = metrics.mean_squared_error(np.exp(y_test), y_preds, squared=False)\n",
    "        \n",
    "    for i, coef in zip(X.columns, np.exp(ridge_cv.coef_)):\n",
    "        print(f\"{i}: {coef}\")\n",
    "    print(f\"intercept: {np.exp(ridge_cv.intercept_)}\")\n",
    "    \n",
    "    return f\"Training R2: {ridge_cv.score(Z_train, y_train)}, Testing R2: {ridge_cv.score(Z_test, y_test)}, MSE: {MSE}, RMSE: {RMSE}\"\n",
    "    \n",
    "log_mod_iteration_rreg(feats_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d683b5-e9b4-46d2-8a00-d12ca95dcfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_qual: 1.0987762905628955\n",
      "year_built: 1.0003232174529473\n",
      "year_remod: 1.0426519416109088\n",
      "total_bsmt_sf: 1.0636634366546767\n",
      "gr_liv_area: 1.133627098687911\n",
      "full_bath: 0.9918178161597343\n",
      "fireplaces: 1.0311686879537127\n",
      "age: 0.9771391861000637\n",
      "garage_area: 1.0248598334939023\n",
      "kitchen_qual_Fa: 0.9759800528263719\n",
      "kitchen_qual_Gd: 0.9604162465012543\n",
      "kitchen_qual_TA: 0.9472563392886116\n",
      "was_remod: 1.0051102781331958\n",
      "bsmt_cat_finished: 1.016300332978322\n",
      "bsmt_cat_unfinished: 0.9824121556123594\n",
      "grg_qual_num: 1.0340336658674736\n",
      "garage_cat_finished: 0.9901853463766699\n",
      "garage_cat_unfinished: 0.9725520594303667\n",
      "garage_cat_rough_finished: 0.984752979750718\n",
      "cond12_feeder_st: 1.0106924261971812\n",
      "cond12_near_park: 1.0167444188794361\n",
      "cond12_near_rr: 1.0091297136376525\n",
      "cond12_norm: 1.025201914161518\n",
      "lotconfig_culdsac: 1.0058482789282661\n",
      "lotconfig_inside: 0.9944630576817284\n",
      "hi_bsmt_exposure: 1.0175037760192966\n",
      "nbr_rank: 1.0383325509573256\n",
      "intercept: 168371.1380929812\n",
      "null_MSE: 6410615844.843487, null_RMSE: 80066.32153935565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Full Data R2: 0.8889332665661638, MSE = 548721470.0822326, RMSE = 23424.804590054377'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_mod_runon_all_rreg(feats):\n",
    "    \n",
    "    # Fit regression to entire data\n",
    "    X = hs[feats]\n",
    "    y = hs['log_price']\n",
    "    \n",
    "    # Scale features\n",
    "    sc_all = StandardScaler()\n",
    "    Z_all = sc_all.fit_transform(X)\n",
    "    \n",
    "    # Run Ridge Regression\n",
    "    r_alphas = np.logspace(0, 5, 150)\n",
    "    ridge_cv_all = RidgeCV(alphas = r_alphas, scoring = 'r2', cv = 10)\n",
    "    ridge_cv_all.fit(Z_all, y)\n",
    "    \n",
    "    # Predict SalePrice for entire data and compare to truth to get residuals\n",
    "    y_preds_all = np.exp(ridge_cv_all.predict(Z_all)) # Undoing the logged price\n",
    "    y_true = hs['SalePrice'] #Can use var from entire dataset\n",
    "    MSE = metrics.mean_squared_error(y_true, y_preds_all)\n",
    "    RMSE = metrics.mean_squared_error(y_true, y_preds_all, squared=False)\n",
    "    \n",
    "    # Use regression to predict SalePrice on Test.csv (unseen) data\n",
    "    # first standard scale\n",
    "    Z_all_test = sc_all.transform(hs_test[feats])\n",
    "    y_preds_all_test = np.exp(ridge_cv_all.predict(Z_all_test))\n",
    "    hs_test['SalePrice'] = y_preds_all_test\n",
    "   \n",
    "    # Null model for comparison\n",
    "    hs['null_pred'] = np.exp(np.mean(y))\n",
    "    null_pred = hs['null_pred']\n",
    "    null_MSE = metrics.mean_squared_error(y_true, null_pred)\n",
    "    null_RMSE = metrics.mean_squared_error(y_true, null_pred, squared=False)\n",
    "    \n",
    "    # Submit Predictions to Kaggle\n",
    "    #submit = hs_test[['Id', 'SalePrice']]\n",
    "    #submit.set_index('Id', inplace=True)\n",
    "    #dt = datetime.datetime.now().strftime(\"%m%d%Y%H\")\n",
    "    #submit.to_csv(f'../datasets/Submissions/Features_Submission_logy_ridreg-{dt}.csv')\n",
    "        \n",
    "    for i, coef in zip(X.columns, np.exp(ridge_cv_all.coef_)):\n",
    "        print(f\"{i}: {coef}\")\n",
    "    print(f\"intercept: {np.exp(ridge_cv_all.intercept_)}\")\n",
    "    print(f\"null_MSE: {null_MSE}, null_RMSE: {null_RMSE}\")\n",
    "\n",
    "    return f\"Full Data R2: {ridge_cv_all.score(Z_all, y)}, MSE = {MSE}, RMSE = {RMSE}\"\n",
    "\n",
    "log_mod_runon_all_rreg(feats_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f6e79-b9f1-4c45-a47e-000f22cfbd66",
   "metadata": {},
   "source": [
    "<span style= 'color:blue'>**Under this linear model using Ridge regularization where the target variable (Sale Price) <u>was</u> log-transformed, our training and testing R^2 were approximately 6% different: 90% and 84%, respectively. This could potentially indicate some overfitting and is interpreted as: ~84% of the variability in Sale Price can be explained by the features used in our model. With an RMSE of 23,424 (fitted on the whole data), this model does a much better job than the null model of predicting Sale Price (null_RMSE: 80,066).**</span>\n",
    "\n",
    "<span style= 'color:blue'>**Some noteable model features included:</span>\n",
    "- <span style= 'color:blue'>**_Kitchen Quality_**: Holding all other variables constant, having a kitchen in Fair/Good/Average quality vs. Excellent quality decreased the predicted Sale Price by up to 5%. Regularization decreased the impact of beta coefficients on our target variable.</span>\n",
    "- <span style= 'color:blue'>**_Living Area Square-Footage (Above and Below Ground)_**: Holding all other variables constant, per every one unit increase in the above ground square-footage, Sale Price was predicted to increase by 13%. Also, per every square-footage increase in basement area, the predicted Sale Price was expected to increase by 4%, holding all else constant.</span>\n",
    "- <span style= 'color:blue'>**_Year Remodeled_**: Holding all other variables constant, per every year increase in remodeling year (i.e., the more recently the property was remodeled), the Sale Price was predicted to increase by 4%.</span>\n",
    "- <span style= 'color:blue'>**_Neighborhood Rank_**: Holding all other variables constant, per every unit increase in neighborhood rank*, the Sale Price was predicted to increase by 4%.</span>\n",
    "\n",
    "<span style= 'color:blue'>*Neighborhood rank = a variable created by scoring neighborhoods based on their rankings in median Sale Price (based on training data), average Overall Quality, average Exterior Quality, average functionality score, and average access/amenities score.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd7b19-b026-4089-839c-d506c964958f",
   "metadata": {},
   "source": [
    "#### Lasso CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c50c5373-9955-4b0e-a2df-ec7573419f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_qual: 1.0944725716213615\n",
      "year_built: 1.0\n",
      "year_remod: 1.0419231822235242\n",
      "total_bsmt_sf: 1.070583287073525\n",
      "gr_liv_area: 1.1337837450897468\n",
      "full_bath: 0.9970236964304473\n",
      "fireplaces: 1.0311751234703737\n",
      "age: 0.9793896642784763\n",
      "garage_area: 1.0270427918308345\n",
      "kitchen_qual_Fa: 0.973797894451564\n",
      "kitchen_qual_Gd: 0.9618578971161179\n",
      "kitchen_qual_TA: 0.950343515974906\n",
      "was_remod: 1.0063322691423373\n",
      "bsmt_cat_finished: 1.008814646012088\n",
      "bsmt_cat_unfinished: 0.9779581242193113\n",
      "grg_qual_num: 1.022571427564969\n",
      "garage_cat_finished: 1.0063610103092122\n",
      "garage_cat_unfinished: 0.9884523377177753\n",
      "garage_cat_rough_finished: 1.0\n",
      "cond12_feeder_st: 1.0065444299238067\n",
      "cond12_near_park: 1.0175998749335589\n",
      "cond12_near_rr: 1.0107084865270726\n",
      "cond12_norm: 1.0234732942574682\n",
      "lotconfig_culdsac: 1.003900989655572\n",
      "lotconfig_inside: 0.9941880223427605\n",
      "hi_bsmt_exposure: 1.017883327936698\n",
      "nbr_rank: 1.0415731551130674\n",
      "intercept: 168613.18234487195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training R2: 0.9030200359412649, Testing R2: 0.8397330711550361, MSE: 597795364.0840014, RMSE: 24449.854070811987'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_mod_iteration_lreg(feats):\n",
    "    \n",
    "    # Fit regression to X_train and y_train (75% of training.csv)\n",
    "    X = hs[feats]\n",
    "    y = hs['log_price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 602)\n",
    "    \n",
    "    # Scale features\n",
    "    sc = StandardScaler()\n",
    "    Z_train = sc.fit_transform(X_train)\n",
    "    Z_test = sc.transform(X_test)\n",
    "    \n",
    "    # Run Lasso Regression\n",
    "    l_alphas = np.logspace(-5, 0, 150)\n",
    "    lasso_cv = LassoCV(alphas = l_alphas, cv = 10, max_iter=75_000)\n",
    "    lasso_cv.fit(Z_train, y_train)\n",
    "            \n",
    "    # Predict SalePrice for 25% testing data within train.csv and compare to truth to get residuals\n",
    "    y_preds = np.exp(lasso_cv.predict(Z_test)) # Undoing the logged price\n",
    "    MSE = metrics.mean_squared_error(np.exp(y_test), y_preds)\n",
    "    RMSE = metrics.mean_squared_error(np.exp(y_test), y_preds, squared=False)\n",
    "        \n",
    "    for i, coef in zip(X.columns, np.exp(lasso_cv.coef_)):\n",
    "        print(f\"{i}: {coef}\")\n",
    "    print(f\"intercept: {np.exp(lasso_cv.intercept_)}\")\n",
    "    \n",
    "    return f\"Training R2: {lasso_cv.score(Z_train, y_train)}, Testing R2: {lasso_cv.score(Z_test, y_test)}, MSE: {MSE}, RMSE: {RMSE}\"\n",
    "    \n",
    "log_mod_iteration_lreg(feats_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ad6751a-dbe9-46ec-8f2b-2c82db34d397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_qual: 1.0988114390483708\n",
      "year_built: 0.8943931103927437\n",
      "year_remod: 1.04293912332863\n",
      "total_bsmt_sf: 1.0637934595213592\n",
      "gr_liv_area: 1.135516634981402\n",
      "full_bath: 0.9904980219939052\n",
      "fireplaces: 1.0305650899065377\n",
      "age: 0.8742009619170019\n",
      "garage_area: 1.0242794015299088\n",
      "kitchen_qual_Fa: 0.974600197611383\n",
      "kitchen_qual_Gd: 0.9567468470703837\n",
      "kitchen_qual_TA: 0.943228153619837\n",
      "was_remod: 1.0054942246382392\n",
      "bsmt_cat_finished: 1.015806163839149\n",
      "bsmt_cat_unfinished: 0.981852822046318\n",
      "grg_qual_num: 1.0473964000332932\n",
      "garage_cat_finished: 0.9648834748558818\n",
      "garage_cat_unfinished: 0.9453320083927481\n",
      "garage_cat_rough_finished: 0.9588618976096734\n",
      "cond12_feeder_st: 1.0119043954238789\n",
      "cond12_near_park: 1.017532614057134\n",
      "cond12_near_rr: 1.0100450190896277\n",
      "cond12_norm: 1.0272554980925512\n",
      "lotconfig_culdsac: 1.0055167741816744\n",
      "lotconfig_inside: 0.9941302362239561\n",
      "hi_bsmt_exposure: 1.0170259557842876\n",
      "nbr_rank: 1.0384953023857268\n",
      "intercept: 168371.1380929812\n",
      "null_MSE: 6410615844.843487, null_RMSE: 80066.32153935565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Full Data R2: 0.8892808391126586, MSE = 545560034.3673917, RMSE = 23357.226598365476'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_mod_runon_all_lreg(feats):\n",
    "    \n",
    "    # Fit regression to entire data\n",
    "    X = hs[feats]\n",
    "    y = hs['log_price']\n",
    "    \n",
    "    # Scale features\n",
    "    sc_all = StandardScaler()\n",
    "    Z_all = sc_all.fit_transform(X)\n",
    "    \n",
    "    # Run Lasso Regression\n",
    "    l_alphas = np.logspace(-5, 0, 150)\n",
    "    lasso_cv_all = LassoCV(alphas = l_alphas, cv = 10, max_iter=75_000)\n",
    "    lasso_cv_all.fit(Z_all, y)\n",
    "    \n",
    "    # Predict SalePrice for entire data and compare to truth to get residuals\n",
    "    y_preds_all = np.exp(lasso_cv_all.predict(Z_all)) # Undoing the logged price\n",
    "    y_true = hs['SalePrice'] #Can use var from entire dataset\n",
    "    MSE = metrics.mean_squared_error(y_true, y_preds_all)\n",
    "    RMSE = metrics.mean_squared_error(y_true, y_preds_all, squared=False)\n",
    "    \n",
    "    # Use regression to predict SalePrice on Test.csv (unseen) data\n",
    "    # first standard scale\n",
    "    Z_all_test = sc_all.transform(hs_test[feats])\n",
    "    y_preds_all_test = np.exp(lasso_cv_all.predict(Z_all_test))\n",
    "    hs_test['SalePrice'] = y_preds_all_test\n",
    "\n",
    "    # Null model for comparison\n",
    "    hs['null_pred'] = np.exp(np.mean(y))\n",
    "    null_pred = hs['null_pred']\n",
    "    null_MSE = metrics.mean_squared_error(y_true, null_pred)\n",
    "    null_RMSE = metrics.mean_squared_error(y_true, null_pred, squared=False)\n",
    "    \n",
    "    # Submit Predictions to Kaggle\n",
    "    submit = hs_test[['Id', 'SalePrice']]\n",
    "    submit.set_index('Id', inplace=True)\n",
    "    dt = datetime.datetime.now().strftime(\"%m%d%Y%H\")\n",
    "    submit.to_csv(f'../datasets/Submissions/Features_Submission_logy_lreg-{dt}.csv')\n",
    "        \n",
    "    for i, coef in zip(X.columns, np.exp(lasso_cv_all.coef_)):\n",
    "        print(f\"{i}: {coef}\")\n",
    "    print(f\"intercept: {np.exp(lasso_cv_all.intercept_)}\")\n",
    "    print(f\"null_MSE: {null_MSE}, null_RMSE: {null_RMSE}\")\n",
    "    \n",
    "    return f\"Full Data R2: {lasso_cv_all.score(Z_all, y)}, MSE = {MSE}, RMSE = {RMSE}\"\n",
    "\n",
    "log_mod_runon_all_lreg(feats_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcbc9ba-de16-405d-9ace-757e7a239401",
   "metadata": {},
   "source": [
    "<span style= 'color:blue'>**Under this linear model using Lasso regularization where the target variable (Sale Price) <u>was</u> log-transformed, our training and testing R^2 were still approximately 6% different: 90% and 84%, respectively. This could potentially indicate some overfitting and is interpreted as: ~84% of the variability in Sale Price can be explained by the features used in our model. With an RMSE of 23,357 (fitted on the whole data), this model does a much better job than the null model of predicting Sale Price (null_RMSE: 80,066).**</span>\n",
    "\n",
    "<span style= 'color:blue'>**Some noteable model features included:</span>\n",
    "- <span style= 'color:blue'>**_Kitchen Quality_**: Holding all other variables constant, having a kitchen in Fair/Good/Average quality vs. Excellent quality decreased the predicted Sale Price by up to 6%. Regularization decreased the impact of beta coefficients on our target variable.</span>\n",
    "- <span style= 'color:blue'>**_Living Area Square-Footage (Above and Below Ground)_**: Holding all other variables constant, per every one unit increase in the above ground square-footage, Sale Price was predicted to increase by 13.5%. Also, per every square-footage increase in basement area, the predicted Sale Price was expected to increase by 6%, holding all else constant.</span>\n",
    "- <span style= 'color:blue'>**_Year Remodeled_**: Holding all other variables constant, per every year increase in remodeling year (i.e., the more recently the property was remodeled), the Sale Price was predicted to increase by 4%.</span>\n",
    "- <span style= 'color:blue'>**_Garage Quality vs. Finished Status_**: Holding all other variables constant, per every one unit increase in the garage quality (ordered from None, Poor, Fair, Average, Good, Excellent), the predicted Sale price was expected to increase by 5%. However, having a finished, rough finished, or unfinished garage, compared to no garage, appeared to be decrease the predicted Sale Price from 4-5.5%, holding all else equal. These results are unexpected and could potentially be due to multicollinearity taking place in the model between these features.</span>\n",
    "- <span style= 'color:blue'>**_Basement Finished Status_**: Holding all other variables constant, having a finished basement predicted an increase of 1.6% in Sale Price, compared to no basement. However, having an unfinished basement actually predicted a 2$ decrease in Sale Price, holding all else equal.</span>\n",
    "- <span style= 'color:blue'>**_Age_**: For every one year increase in age of property, the Sale Price was predicted to decrease by 13%, holding all other variables constant.</span>\n",
    "- <span style= 'color:blue'>**_Neighborhood Rank_**: Holding all other variables constant, per every unit increase in neighborhood rank*, the Sale Price was predicted to increase by 4%.</span>\n",
    "\n",
    "<span style= 'color:blue'>*Neighborhood rank = a variable created by scoring neighborhoods based on their rankings in median Sale Price (based on training data), average Overall Quality, average Exterior Quality, average functionality score, and average access/amenities score</span>\n",
    "\n",
    "<span style= 'color: blue'> **While the training R^2 (from Z_train) is larger than the testing R^2 (from Z_test), neither Ridge nor Lasso CV regularization appear to be addressing the overfitting. This has been the case after several iterations of changing the strength of the regularization (alpha), as well as removing variables to make the model simpler, and increasing/decreasing the number of cross-validations performed. Each scenario resulted in the RMSE score increasing and R^2 either remaining constant or decreasing slightly.**</span> \n",
    "\n",
    "<span style= 'color: blue'> **Our final model will be the Lasso-regularized model using log-transformed Sale Price. This model achieved nearly the same metrics as the non-Lasso version, however, using the regularized version may be beneficial on unseen data as it does appear that the model is overfit.**</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48bb8b96-e815-4f1f-be12-cab72244af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBMISSION HISTORY\n",
    "\n",
    "# 6/3 10P submission = ['overall_qual', 'year_built', 'year_remod', 'total_bsmt_sf', 'gr_liv_area', 'full_bath', 'fireplaces', 'age', 'garage_area', 'kitchen_qual_Fa', 'kitchen_qual_Gd', 'kitchen_qual_TA', 'was_remod', 'bsmt_cat_finished','bsmt_cat_unfinished', 'grg_qual_num', 'garage_cat_finished', 'garage_cat_unfinished', 'cond12_feeder_st', 'cond12_near_park', 'cond12_near_rr', 'cond12_norm', 'lotconfig_culdsac', 'lotconfig_inside', 'hi_bsmt_exposure', 'nbr_rank']\n",
    "# 6/3 8:30P submission = ['overall_qual', 'year_built', 'year_remod', 'total_bsmt_sf', 'gr_liv_area', 'full_bath', 'fireplaces', 'garage_area', 'age', 'was_remod', 'bsmt_cat_finished','bsmt_cat_unfinished']\n",
    "# 6/2 submission = ['overall_qual', 'year_built', 'year_remod', 'total_bsmt_sf', 'gr_liv_area', 'full_bath', 'fireplaces', 'garage_area']\n",
    "# first submission = ['Overall Qual', 'Year Built', 'Year Remod/Add', 'BsmtFin SF 1', 'Total Bsmt SF', 'Gr Liv Area', 'Full Bath', 'Fireplaces', 'Garage Area']\n",
    "# in-class submission = ['Overall Qual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc841266-058d-4674-9051-5912adeb384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Lasso Regl\n",
    "\n",
    "# 'Full Data R2: 0.8891974819498465, MSE = 546453367.2372748, RMSE = 23376.342041416035'\n",
    "# feats_updated = ['overall_qual', 'year_built', 'year_remod', 'total_bsmt_sf', 'gr_liv_area', 'full_bath', 'fireplaces', 'age', 'garage_area', 'kitchen_qual_Fa', 'kitchen_qual_Gd', 'kitchen_qual_TA', 'was_remod', 'bsmt_cat_finished','bsmt_cat_unfinished', 'grg_qual_num', 'garage_cat_finished', 'garage_cat_unfinished', 'cond12_feeder_st', 'cond12_near_park', 'cond12_near_rr', 'cond12_norm', 'lotconfig_culdsac', 'lotconfig_inside', 'hi_bsmt_exposure', 'nbr_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c5f4dcb-4673-4426-a0d8-5b5f16052d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W/ Lasso Regl\n",
    "# 'Full Data R2: 0.8891958486538678, MSE = 546493452.084716, RMSE = 23377.19940635995'\n",
    "# feats_updated = ['overall_qual', 'year_built', 'year_remod', 'total_bsmt_sf', 'gr_liv_area', 'full_bath', 'fireplaces', 'age', 'garage_area', 'kitchen_qual_Fa', 'kitchen_qual_Gd', 'kitchen_qual_TA', 'was_remod', 'bsmt_cat_finished','bsmt_cat_unfinished', 'grg_qual_num', 'garage_cat_finished', 'garage_cat_unfinished', 'cond12_feeder_st',  'cond12_near_park', 'cond12_near_rr', 'cond12_norm', 'lotconfig_culdsac', 'lotconfig_inside', 'hi_bsmt_exposure', 'nbr_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2d8a557-a50a-4dcc-a2a5-078f71276b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factors that ended up not being important:\n",
    "\n",
    "# - Any condition indicators\n",
    "# - Fireplace and Garage Quality\n",
    "# - Pool (1/0)\n",
    "# - Amenities Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9634026-8c19-4f27-97d4-675f940f636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpreting Log transformations in a linear model: https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
