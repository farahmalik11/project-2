{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53208730-74eb-422c-996b-e9409d717ba4",
   "metadata": {},
   "source": [
    "# Ames Housing Data: Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad1cd23-f9b7-480a-bb00-a932d389ce12",
   "metadata": {},
   "source": [
    "This notebook stores the final model chosen for our analysis. This model has the highest R^2 whilst minimzing RMSE compared to all other options tested. The chosen Linear Regression model is performed with a <u>Log-Transformed Target Variable</u> (Sale Price) and with <u>LassoCV regularization</u>.\n",
    "\n",
    "For more information on the initial data cleaning, exploration, and visualization see the [initial notebook](../code/01_EDA_and_Cleaning.ipynb) of this analysis. For transforming our variables into model-ready form, see the [second notebook](../code/02_Feature_Engineering.ipynb) of this analysis.\n",
    "\n",
    "For more information on the background, [data](https://jse.amstat.org/v19n3/decock/DataDocumentation.txt), and a summary of methods and findings, please see the associated [README](../Farah_Malik_Proj2_README.md) for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ba231c-7b24-4204-9c58-96bed197ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import missingno as msno\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder #, PolynomialFeatures\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import datetime\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163731c0-cba9-4683-a801-10abda4f1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = pd.read_csv('./datasets/Clean/train.csv', na_values=['NaN', '', 'Missing'], keep_default_na=False)\n",
    "hs_test = pd.read_csv('./datasets/Clean/test.csv', na_values=['NaN', '', 'Missing'], keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4990310-d7bd-48df-9128-1eb3e23a4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE FEATURES FOR TESTING HERE\n",
    "feats_updated = ['overall_qual', 'year_built', 'year_remod', 'total_bsmt_sf', 'gr_liv_area', 'full_bath', 'fireplaces', 'age', 'garage_area', 'kitchen_qual_Fa',\n",
    " 'kitchen_qual_Gd', 'kitchen_qual_TA', 'was_remod', 'bsmt_cat_finished','bsmt_cat_unfinished', 'grg_qual_num', 'garage_cat_finished', 'garage_cat_unfinished', 'garage_cat_rough_finished', 'cond12_feeder_st',\n",
    " 'cond12_near_park', 'cond12_near_rr', 'cond12_norm', 'lotconfig_culdsac', 'lotconfig_inside', 'hi_bsmt_exposure', 'nbr_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b80d75-3a9a-47d3-8833-7a00d0ac9cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_qual: 1.0944725716213615\n",
      "year_built: 1.0\n",
      "year_remod: 1.0419231822235242\n",
      "total_bsmt_sf: 1.070583287073525\n",
      "gr_liv_area: 1.1337837450897468\n",
      "full_bath: 0.9970236964304473\n",
      "fireplaces: 1.0311751234703737\n",
      "age: 0.9793896642784763\n",
      "garage_area: 1.0270427918308345\n",
      "kitchen_qual_Fa: 0.973797894451564\n",
      "kitchen_qual_Gd: 0.9618578971161179\n",
      "kitchen_qual_TA: 0.950343515974906\n",
      "was_remod: 1.0063322691423373\n",
      "bsmt_cat_finished: 1.008814646012088\n",
      "bsmt_cat_unfinished: 0.9779581242193113\n",
      "grg_qual_num: 1.022571427564969\n",
      "garage_cat_finished: 1.0063610103092122\n",
      "garage_cat_unfinished: 0.9884523377177753\n",
      "garage_cat_rough_finished: 1.0\n",
      "cond12_feeder_st: 1.0065444299238067\n",
      "cond12_near_park: 1.0175998749335589\n",
      "cond12_near_rr: 1.0107084865270726\n",
      "cond12_norm: 1.0234732942574682\n",
      "lotconfig_culdsac: 1.003900989655572\n",
      "lotconfig_inside: 0.9941880223427605\n",
      "hi_bsmt_exposure: 1.017883327936698\n",
      "nbr_rank: 1.0415731551130674\n",
      "intercept: 168613.18234487195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training R2: 0.9030200359412649, Testing R2: 0.8397330711550361, MSE: 597795364.0840014, RMSE: 24449.854070811987'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_mod_iteration_lreg(feats):\n",
    "    \n",
    "    # Fit regression to X_train and y_train (75% of training.csv)\n",
    "    X = hs[feats]\n",
    "    y = hs['log_price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 602)\n",
    "    \n",
    "    # Scale features\n",
    "    sc = StandardScaler()\n",
    "    Z_train = sc.fit_transform(X_train)\n",
    "    Z_test = sc.transform(X_test)\n",
    "    \n",
    "    # Run Lasso Regression\n",
    "    l_alphas = np.logspace(-5, 0, 150)\n",
    "    lasso_cv = LassoCV(alphas = l_alphas, cv = 10, max_iter=75_000)\n",
    "    lasso_cv.fit(Z_train, y_train)\n",
    "            \n",
    "    # Predict SalePrice for 25% testing data within train.csv and compare to truth to get residuals\n",
    "    y_preds = np.exp(lasso_cv.predict(Z_test)) # Undoing the logged price\n",
    "    MSE = metrics.mean_squared_error(np.exp(y_test), y_preds)\n",
    "    RMSE = metrics.mean_squared_error(np.exp(y_test), y_preds, squared=False)\n",
    "        \n",
    "    for i, coef in zip(X.columns, np.exp(lasso_cv.coef_)):\n",
    "        print(f\"{i}: {coef}\")\n",
    "    print(f\"intercept: {np.exp(lasso_cv.intercept_)}\")\n",
    "    \n",
    "    return f\"Training R2: {lasso_cv.score(Z_train, y_train)}, Testing R2: {lasso_cv.score(Z_test, y_test)}, MSE: {MSE}, RMSE: {RMSE}\"\n",
    "    \n",
    "log_mod_iteration_lreg(feats_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4245aa-4a20-46e6-afd2-bbf17b3429d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_qual: 1.0988114390483708\n",
      "year_built: 0.8943931103927437\n",
      "year_remod: 1.04293912332863\n",
      "total_bsmt_sf: 1.0637934595213592\n",
      "gr_liv_area: 1.135516634981402\n",
      "full_bath: 0.9904980219939052\n",
      "fireplaces: 1.0305650899065377\n",
      "age: 0.8742009619170019\n",
      "garage_area: 1.0242794015299088\n",
      "kitchen_qual_Fa: 0.974600197611383\n",
      "kitchen_qual_Gd: 0.9567468470703837\n",
      "kitchen_qual_TA: 0.943228153619837\n",
      "was_remod: 1.0054942246382392\n",
      "bsmt_cat_finished: 1.015806163839149\n",
      "bsmt_cat_unfinished: 0.981852822046318\n",
      "grg_qual_num: 1.0473964000332932\n",
      "garage_cat_finished: 0.9648834748558818\n",
      "garage_cat_unfinished: 0.9453320083927481\n",
      "garage_cat_rough_finished: 0.9588618976096734\n",
      "cond12_feeder_st: 1.0119043954238789\n",
      "cond12_near_park: 1.017532614057134\n",
      "cond12_near_rr: 1.0100450190896277\n",
      "cond12_norm: 1.0272554980925512\n",
      "lotconfig_culdsac: 1.0055167741816744\n",
      "lotconfig_inside: 0.9941302362239561\n",
      "hi_bsmt_exposure: 1.0170259557842876\n",
      "nbr_rank: 1.0384953023857268\n",
      "intercept: 168371.1380929812\n",
      "null_MSE: 6410615844.843487, null_RMSE: 80066.32153935565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Full Data R2: 0.8892808391126586, MSE = 545560034.3673917, RMSE = 23357.226598365476'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_mod_runon_all_lreg(feats):\n",
    "    \n",
    "    # Fit regression to entire data\n",
    "    X = hs[feats]\n",
    "    y = hs['log_price']\n",
    "    \n",
    "    # Scale features\n",
    "    sc_all = StandardScaler()\n",
    "    Z_all = sc_all.fit_transform(X)\n",
    "    \n",
    "    # Run Ridge Regression\n",
    "    l_alphas = np.logspace(-5, 0, 150)\n",
    "    lasso_cv_all = LassoCV(alphas = l_alphas, cv = 10, max_iter=75_000)\n",
    "    lasso_cv_all.fit(Z_all, y)\n",
    "    \n",
    "    # Predict SalePrice for entire data and compare to truth to get residuals\n",
    "    y_preds_all = np.exp(lasso_cv_all.predict(Z_all)) # Undoing the logged price\n",
    "    y_true = hs['SalePrice'] #Can use var from entire dataset\n",
    "    MSE = metrics.mean_squared_error(y_true, y_preds_all)\n",
    "    RMSE = metrics.mean_squared_error(y_true, y_preds_all, squared=False)\n",
    "    \n",
    "    # Use regression to predict SalePrice on Test.csv (unseen) data\n",
    "    # first standard scale\n",
    "    Z_all_test = sc_all.transform(hs_test[feats])\n",
    "    y_preds_all_test = np.exp(lasso_cv_all.predict(Z_all_test))\n",
    "    hs_test['SalePrice'] = y_preds_all_test\n",
    "\n",
    "    # Null model for comparison\n",
    "    hs['null_pred'] = np.exp(np.mean(y))\n",
    "    null_pred = hs['null_pred']\n",
    "    null_MSE = metrics.mean_squared_error(y_true, null_pred)\n",
    "    null_RMSE = metrics.mean_squared_error(y_true, null_pred, squared=False)\n",
    "    \n",
    "    # Submit Predictions to Kaggle\n",
    "    submit = hs_test[['Id', 'SalePrice']]\n",
    "    submit.set_index('Id', inplace=True)\n",
    "    dt = datetime.datetime.now().strftime(\"%m%d%Y%H\")\n",
    "    submit.to_csv(f'./datasets/Submissions/Features_Submission_logy_lreg-{dt}.csv')\n",
    "        \n",
    "    for i, coef in zip(X.columns, np.exp(lasso_cv_all.coef_)):\n",
    "        print(f\"{i}: {coef}\")\n",
    "    print(f\"intercept: {np.exp(lasso_cv_all.intercept_)}\")\n",
    "    print(f\"null_MSE: {null_MSE}, null_RMSE: {null_RMSE}\")\n",
    "    \n",
    "    return f\"Full Data R2: {lasso_cv_all.score(Z_all, y)}, MSE = {MSE}, RMSE = {RMSE}\"\n",
    "\n",
    "log_mod_runon_all_lreg(feats_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f637a1e-1742-4b5b-903c-53366f1a9204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below attempts to look at OLS measures on our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb5a9fe-266f-43b7-a2f5-9876e0a83e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hs[feats_updated]\n",
    "y = hs['log_price']\n",
    "    \n",
    "# Scale features\n",
    "sc_all = StandardScaler()\n",
    "Z_all = sc_all.fit_transform(X)\n",
    "    \n",
    "# Run Ridge Regression\n",
    "l_alphas = np.logspace(-5, 0, 150)\n",
    "lasso_cv_all = LassoCV(alphas = l_alphas, cv = 10, max_iter=75_000)\n",
    "lasso_cv_all.fit(Z_all, y)\n",
    "    \n",
    "# Predict SalePrice for entire data and compare to truth to get residuals\n",
    "y_preds_all = np.exp(lasso_cv_all.predict(Z_all)) # Undoing the logged priceZ_wc = sm.add_constant(Z_all)\n",
    "y_true = hs['SalePrice']\n",
    "\n",
    "Z_all_test = sc_all.transform(hs_test[feats_updated])\n",
    "y_preds_all_test = np.exp(lasso_cv_all.predict(Z_all_test))\n",
    "hs_test['SalePrice'] = y_preds_all_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "534c481c-6ee7-4c39-9fb6-066b52d1ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_wc = sm.add_constant(Z_all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ade147-dce0-4d73-b814-8cb4c78098e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.OLS(y_preds_all_test, Z_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "791b1ca3-3eb9-43be-ad4c-118cfd1ecb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = sm.OLS(y_preds_all_test, Z_wc).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19729239-2d04-492d-b585-73218d1a8ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.939</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.937</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   482.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 05 Jun 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:30:36</td>     <th>  Log-Likelihood:    </th> <td> -9913.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   878</td>      <th>  AIC:               </th> <td>1.988e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   850</td>      <th>  BIC:               </th> <td>2.002e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    27</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 1.816e+05</td> <td>  681.538</td> <td>  266.460</td> <td> 0.000</td> <td>  1.8e+05</td> <td> 1.83e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 1.725e+04</td> <td> 1240.256</td> <td>   13.907</td> <td> 0.000</td> <td> 1.48e+04</td> <td> 1.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-2.185e+04</td> <td> 1.54e+04</td> <td>   -1.423</td> <td> 0.155</td> <td> -5.2e+04</td> <td> 8295.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 3959.0809</td> <td> 1047.836</td> <td>    3.778</td> <td> 0.000</td> <td> 1902.432</td> <td> 6015.730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 1.517e+04</td> <td> 1009.892</td> <td>   15.019</td> <td> 0.000</td> <td> 1.32e+04</td> <td> 1.71e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 3.116e+04</td> <td> 1079.057</td> <td>   28.881</td> <td> 0.000</td> <td>  2.9e+04</td> <td> 3.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-5023.0588</td> <td>  999.311</td> <td>   -5.027</td> <td> 0.000</td> <td>-6984.466</td> <td>-3061.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> 3428.8273</td> <td>  758.889</td> <td>    4.518</td> <td> 0.000</td> <td> 1939.312</td> <td> 4918.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  -2.8e+04</td> <td> 1.52e+04</td> <td>   -1.843</td> <td> 0.066</td> <td>-5.78e+04</td> <td> 1812.561</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 5317.0583</td> <td> 1030.890</td> <td>    5.158</td> <td> 0.000</td> <td> 3293.669</td> <td> 7340.447</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>-8810.8131</td> <td>  812.975</td> <td>  -10.838</td> <td> 0.000</td> <td>-1.04e+04</td> <td>-7215.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>-2.898e+04</td> <td> 1568.004</td> <td>  -18.481</td> <td> 0.000</td> <td>-3.21e+04</td> <td>-2.59e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>-3.212e+04</td> <td> 1802.759</td> <td>  -17.818</td> <td> 0.000</td> <td>-3.57e+04</td> <td>-2.86e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> 2630.0624</td> <td>  856.870</td> <td>    3.069</td> <td> 0.002</td> <td>  948.233</td> <td> 4311.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>-7415.3319</td> <td> 2186.853</td> <td>   -3.391</td> <td> 0.001</td> <td>-1.17e+04</td> <td>-3123.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>-1.354e+04</td> <td> 2126.024</td> <td>   -6.370</td> <td> 0.000</td> <td>-1.77e+04</td> <td>-9369.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> 2608.9569</td> <td> 1866.497</td> <td>    1.398</td> <td> 0.163</td> <td>-1054.527</td> <td> 6272.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>-2427.1093</td> <td> 3700.591</td> <td>   -0.656</td> <td> 0.512</td> <td>-9690.478</td> <td> 4836.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>-6424.9377</td> <td> 4103.572</td> <td>   -1.566</td> <td> 0.118</td> <td>-1.45e+04</td> <td> 1629.384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>-5962.9285</td> <td> 3863.103</td> <td>   -1.544</td> <td> 0.123</td> <td>-1.35e+04</td> <td> 1619.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td> 2752.2379</td> <td> 1107.997</td> <td>    2.484</td> <td> 0.013</td> <td>  577.508</td> <td> 4926.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td> 3615.2140</td> <td>  872.762</td> <td>    4.142</td> <td> 0.000</td> <td> 1902.193</td> <td> 5328.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td> 1998.0283</td> <td> 1049.238</td> <td>    1.904</td> <td> 0.057</td> <td>  -61.374</td> <td> 4057.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td> 5505.1051</td> <td> 1522.891</td> <td>    3.615</td> <td> 0.000</td> <td> 2516.038</td> <td> 8494.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>  986.1232</td> <td>  797.695</td> <td>    1.236</td> <td> 0.217</td> <td> -579.561</td> <td> 2551.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>-1837.4763</td> <td>  736.118</td> <td>   -2.496</td> <td> 0.013</td> <td>-3282.298</td> <td> -392.655</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td> 5974.8532</td> <td>  767.473</td> <td>    7.785</td> <td> 0.000</td> <td> 4468.488</td> <td> 7481.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td> 5286.4801</td> <td> 1359.630</td> <td>    3.888</td> <td> 0.000</td> <td> 2617.854</td> <td> 7955.106</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1082.834</td> <th>  Durbin-Watson:     </th>  <td>   1.986</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>210674.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 6.034</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>77.921</td>  <th>  Cond. No.          </th>  <td>    86.2</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.939\n",
       "Model:                            OLS   Adj. R-squared:                  0.937\n",
       "Method:                 Least Squares   F-statistic:                     482.3\n",
       "Date:                Mon, 05 Jun 2023   Prob (F-statistic):               0.00\n",
       "Time:                        07:30:36   Log-Likelihood:                -9913.3\n",
       "No. Observations:                 878   AIC:                         1.988e+04\n",
       "Df Residuals:                     850   BIC:                         2.002e+04\n",
       "Df Model:                          27                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       1.816e+05    681.538    266.460      0.000     1.8e+05    1.83e+05\n",
       "x1          1.725e+04   1240.256     13.907      0.000    1.48e+04    1.97e+04\n",
       "x2         -2.185e+04   1.54e+04     -1.423      0.155    -5.2e+04    8295.888\n",
       "x3          3959.0809   1047.836      3.778      0.000    1902.432    6015.730\n",
       "x4          1.517e+04   1009.892     15.019      0.000    1.32e+04    1.71e+04\n",
       "x5          3.116e+04   1079.057     28.881      0.000     2.9e+04    3.33e+04\n",
       "x6         -5023.0588    999.311     -5.027      0.000   -6984.466   -3061.652\n",
       "x7          3428.8273    758.889      4.518      0.000    1939.312    4918.343\n",
       "x8           -2.8e+04   1.52e+04     -1.843      0.066   -5.78e+04    1812.561\n",
       "x9          5317.0583   1030.890      5.158      0.000    3293.669    7340.447\n",
       "x10        -8810.8131    812.975    -10.838      0.000   -1.04e+04   -7215.139\n",
       "x11        -2.898e+04   1568.004    -18.481      0.000   -3.21e+04   -2.59e+04\n",
       "x12        -3.212e+04   1802.759    -17.818      0.000   -3.57e+04   -2.86e+04\n",
       "x13         2630.0624    856.870      3.069      0.002     948.233    4311.891\n",
       "x14        -7415.3319   2186.853     -3.391      0.001   -1.17e+04   -3123.067\n",
       "x15        -1.354e+04   2126.024     -6.370      0.000   -1.77e+04   -9369.279\n",
       "x16         2608.9569   1866.497      1.398      0.163   -1054.527    6272.441\n",
       "x17        -2427.1093   3700.591     -0.656      0.512   -9690.478    4836.259\n",
       "x18        -6424.9377   4103.572     -1.566      0.118   -1.45e+04    1629.384\n",
       "x19        -5962.9285   3863.103     -1.544      0.123   -1.35e+04    1619.411\n",
       "x20         2752.2379   1107.997      2.484      0.013     577.508    4926.968\n",
       "x21         3615.2140    872.762      4.142      0.000    1902.193    5328.235\n",
       "x22         1998.0283   1049.238      1.904      0.057     -61.374    4057.430\n",
       "x23         5505.1051   1522.891      3.615      0.000    2516.038    8494.172\n",
       "x24          986.1232    797.695      1.236      0.217    -579.561    2551.807\n",
       "x25        -1837.4763    736.118     -2.496      0.013   -3282.298    -392.655\n",
       "x26         5974.8532    767.473      7.785      0.000    4468.488    7481.218\n",
       "x27         5286.4801   1359.630      3.888      0.000    2617.854    7955.106\n",
       "==============================================================================\n",
       "Omnibus:                     1082.834   Durbin-Watson:                   1.986\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           210674.817\n",
       "Skew:                           6.034   Prob(JB):                         0.00\n",
       "Kurtosis:                      77.921   Cond. No.                         86.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3381080-9b52-4395-ab81-99453c7b2bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
